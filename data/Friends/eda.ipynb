{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process script of Friends TV Show in order to create dialogue dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read episodes scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogues = []\n",
    "\n",
    "scene_id = -1\n",
    "for ep_path in sorted(Path(\"episodes/\").iterdir()):    \n",
    "    with open(ep_path, 'r') as file:        \n",
    "        for i, line in enumerate(file):\n",
    "            if line.casefold().startswith((\"written\",\"(\",\"{\")):\n",
    "                continue\n",
    "            if line.casefold().startswith(\"[\"):\n",
    "                scene_id += 1\n",
    "                continue\n",
    "            try:           \n",
    "                character,text = line.split(\":\",maxsplit=1)\n",
    "                character = re.sub(r\"\\(.*\\)\",\"\",character)\n",
    "                text = re.sub(r\"\\(.*\\)\",\"\",text)\n",
    "                row = {\"character\": character.lower(), \"text\": text.strip(),\"episode\":ep_path.stem,\"scene\":scene_id}\n",
    "                dialogues.append(row)\n",
    "            except:                    \n",
    "                continue\n",
    "                # print(f\"ERROR: {ep_path.stem}; Line: {i}\")                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = dialogues)\n",
    "df.to_csv(\"friends_dialog.csv\",index=False)\n",
    "# df = pd.read_csv(\"friends_dialog.csv\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dialog pairs for one character in each scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_pairs = []\n",
    "curr_char = None\n",
    "base_ut = None\n",
    "cur_scene = 0\n",
    "for i,row in df.iterrows():\n",
    "    char = row[\"character\"]\n",
    "    if curr_char is None or char == curr_char or row[\"scene\"] != cur_scene:\n",
    "        curr_char = char\n",
    "        base_ut = row[\"text\"]\n",
    "        cur_scene = row[\"scene\"]\n",
    "        continue\n",
    "    dialog_pairs.append((base_ut,row[\"text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dialog pairs for each character in each scene (a lot of utterances are repeated across dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes_start_df = df[df[\"scene\"].ne(df[\"scene\"].shift())]\n",
    "scenes_end = {int(scene):i for i,scene in scenes_start_df[\"scene\"].shift().iloc[1:].iteritems()}\n",
    "dialog_pairs = []\n",
    "for (char,scene),group in df.groupby([\"character\",\"scene\"],sort=False):\n",
    "    char_indices = group.index.tolist()\n",
    "    indices_groups = []\n",
    "    try:\n",
    "        for i in range(char_indices[0],scenes_end[scene]):\n",
    "            if i in char_indices:\n",
    "                indices_groups.append([])\n",
    "            else:\n",
    "                indices_groups[-1].append(i)\n",
    "        \n",
    "        for char_idx, idx_group in zip(char_indices,indices_groups):\n",
    "            base_ut = df.loc[[char_idx] * len(idx_group)][\"text\"].tolist()\n",
    "            answers = df.loc[idx_group][\"text\"].tolist()\n",
    "            dialog_pairs.extend(list(zip(base_ut,answers)))       \n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ut = dialog_pairs[0][0]\n",
    "new_dialog_pairs = [dialog_pairs[0]]\n",
    "for pair in dialog_pairs[1:]:\n",
    "    if pair[0] != base_ut:\n",
    "        new_dialog_pairs.append(pair)\n",
    "        base_ut = pair[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d, test_d = train_test_split(new_dialog_pairs,test_size=0.2,random_state=42,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d,val_d = train_test_split(test_d,test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(dialog_pairs,split):\n",
    "    with open(f\"{split}.txt\",\"w\") as f:\n",
    "        for q,a in dialog_pairs:\n",
    "            line = f\"{q}|{a}\\n\"\n",
    "            f.write(line)\n",
    "write_file(train_d,\"train\")\n",
    "write_file(test_d,\"test\")\n",
    "write_file(val_d,\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b54abc5b2bb490835a5d529b15edeca193d46da8b42d40b773d898688a95f3d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
